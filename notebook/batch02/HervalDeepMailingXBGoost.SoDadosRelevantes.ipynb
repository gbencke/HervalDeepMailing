{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import gc\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import dateutil.parser as parser\n",
    "import os.path\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, confusion_matrix\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proporcao_train = 0.9\n",
    "proporcao_test = 0.1\n",
    "\n",
    "log_location = \"../../logs/\"\n",
    "arquivo_pagantes_norm = \"../../data/batch02/intermediate/Herval.normalized.pickle\"\n",
    "arquivo_pagantes_norm_train_x = \"../../data/batch02/intermediate/Herval.normalized.train.x.pickle\"\n",
    "\n",
    "txt_dump_model = \"../../data/batch02/intermediate/model_generated.txt\"\n",
    "txt_feat_map_model = \"../../data/batch02/intermediate/feat_map_generated.txt\"\n",
    "\n",
    "output_folder= \"../../data/batch02/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(message)s\",\n",
    "                    level=logging.DEBUG,\n",
    "                    filename=os.path.join(log_location,'xgboost.log.' + datetime.now().strftime(\"%Y%m%d%H%M%S.%f\") + '.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(msg):\n",
    "    logging.debug(msg)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Carregando Pickling normalizado:{}\".format(arquivo_pagantes_norm))    \n",
    "pagantes = pd.read_pickle(arquivo_pagantes_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pagantes = len(pagantes.index)\n",
    "print_log(\"Total pagantes:{}\".format(total_pagantes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column_reference(header_chamadas_x,arquivo_df_pickled_norm_train_x):\n",
    "    print_log(\"Criando Arquivo de referencia de colunas...\")\n",
    "    with open(arquivo_df_pickled_norm_train_x+\".txt\",\"w\") as f:\n",
    "        counter = 0\n",
    "        lista_header = list(header_chamadas_x.columns.values)\n",
    "        for header in lista_header:\n",
    "            f.write(\"{}-{}\\n\".format(counter,header))\n",
    "            counter=counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Criando dataframes de train e teste...\")\n",
    "pagantes = pagantes.sample(int(len(pagantes.index)))\n",
    "pagantes_train = pagantes.tail(int(len(pagantes.index) * proporcao_train))\n",
    "pagantes_test = pagantes.head(int(len(pagantes.index) * proporcao_test))\n",
    "del pagantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_column_reference(pagantes_train.loc[:, :'NORM_CONTRATO_ATRASO'].head(1), arquivo_pagantes_norm_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes_train_x = pagantes_train.loc[:, :'NORM_VALOR_DIVIDA']\n",
    "pagantes_train_y = pagantes_train.loc[:, 'PAGOU':'PAGOU']\n",
    "\n",
    "pagantes_test_x = pagantes_test.loc[:, :'NORM_VALOR_DIVIDA']\n",
    "pagantes_test_y = pagantes_test.loc[:, 'PAGOU':'PAGOU']\n",
    "\n",
    "colunas_x = pagantes_train_x.columns.values\n",
    "colunas_y = pagantes_train_y.columns.values\n",
    "\n",
    "pagantes_train_x = pagantes_train_x.as_matrix()\n",
    "pagantes_train_y = pagantes_train_y.as_matrix()\n",
    "\n",
    "pagantes_test_x = pagantes_test_x.as_matrix()\n",
    "pagantes_test_y = pagantes_test_y.as_matrix()\n",
    "\n",
    "colunas_x = [x for x in colunas_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1 = \"Train - Pagantes Detectados {} num universo de {}\".format(len([y for y in pagantes_train_y if y >0]),len(pagantes_train_y))\n",
    "msg2 = \"Test - Pagantes Detectados {} num universo de {}\".format(len([y for y in pagantes_test_y if y >0]),len(pagantes_test_y))\n",
    "print_log(msg1)\n",
    "print_log(msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_trees = 5\n",
    "max_trees = 300\n",
    "model_batch = datetime.now().strftime(\"%Y%m%d.%H%M%S\")\n",
    "for x in range(min_trees, max_trees):\n",
    "    param = {}\n",
    "    param['eta'] = 0.1\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['eval_metric'] = 'auc'\n",
    "    param['tree_method'] = 'exact'\n",
    "    param['silent'] = 0\n",
    "    param['max_depth'] = 3\n",
    "    num_round = x\n",
    "    gc.collect()\n",
    "    #print_log(\"Starting model for params:{}\".format(param))\n",
    "    dtrain = xgb.DMatrix(pagantes_train_x, pagantes_train_y, feature_names = colunas_x)\n",
    "    dtest = xgb.DMatrix(pagantes_test_x, pagantes_test_y, feature_names = colunas_x)\n",
    "    train_labels = dtrain.get_label()\n",
    "    ratio = float(np.sum(train_labels == 0)) / np.sum(train_labels == 1) \n",
    "    param['scale_pos_weight'] = ratio\n",
    "    #print_log(\"ratio:{}\".format(ratio))\n",
    "    gpu_res = {}\n",
    "    booster = xgb.train(param, dtrain, num_round, evals=[], evals_result=gpu_res)\n",
    "    \n",
    "    booster.dump_model(os.path.join(output_folder,\"{}.{}.txt\".format(model_batch,x)))\n",
    "    #plot_importance(booster)\n",
    "    #plt.savefig(os.path.join(output_folder,\"{}.{}.png\".format(model_batch,x)))    \n",
    "    print_log(sorted( ((v,k) for k,v in booster.get_score().items()), reverse=True))\n",
    "    train_y_pred = booster.predict(dtrain)\n",
    "    train_predictions = np.array([value for value in train_y_pred])\n",
    "    #print_log(\"{}, {}\".format(pagantes_train_y.shape, train_predictions.shape))\n",
    "    #print_log(\"{}, {}\".format(pagantes_train_y.dtype, train_predictions.dtype))\n",
    "    pagantes_train_y = pagantes_train_y.astype('float32')\n",
    "    train_predictions = train_predictions.astype('float32').round()\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(np.squeeze(pagantes_train_y), np.squeeze(train_predictions)).ravel()\n",
    "    print_log(\"True Positive:{} True Negative:{} False Positive:{} False Negative:{},  {}% de acerto\".format(tp, tn, fp, fn, (1 - ((fp+fn)/ (tp+tn))) * 100 ))\n",
    "    save_file = os.path.join(output_folder,\"{}.{}.model\".format(model_batch,x))\n",
    "    with open(save_file, 'wb') as fp:\n",
    "        pickle.dump(booster, fp)    \n",
    "    #print_log(\"Model saved as {}\".format(save_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
