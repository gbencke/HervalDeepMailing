{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herval Deep Mailing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse modulo cria um dataframe do tipo pandas que contem todas as colunas normalizadas, ou seja, valores transpostos entre 0.0 e 1.0. Importante notar que a entrada dessa operacao eh uma planilha em excel, que deve ter as seguintes colunas:\n",
    "    \n",
    "* CPF: Valor String\n",
    "* CLIENTE_VALOR_DIVIDA: Valor Numerico (** Obrigatorio **)\n",
    "* CONTRATO_ATRASO: Valor Numerico (** Obrigatorio **)\n",
    "* RENDA_PRESUMIDA: Valor Numerico (** Nao eh Obrigatorio **)\n",
    "* ESCOLARIDADE: Valor Numerico (** Nao eh Obrigatorio **)\n",
    "* CLASSE_SOCIAL: Valor Numerico (** Nao eh Obrigatorio **)\n",
    "    \n",
    "No caso de ser um excel para treinamento de modelos eh necessario tambem informar a coluna PAGOU que tera o valor 0 ou 1, e eh a variavel alvo a ser usada.    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importacao dos modulos necessarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil.parser as parser\n",
    "import os\n",
    "import os.path\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if 'HERVAL_FROM_SOURCE' in os.environ:\n",
    "    running_in_jupyter = False\n",
    "else:\n",
    "    import matplotlib.pyplot as plt\n",
    "    running_in_jupyter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'HERVAL_DATA_FOLDER' in os.environ:\n",
    "    data_folder = os.environ['HERVAL_DATA_FOLDER']\n",
    "else:\n",
    "    data_folder = \"../../\"\n",
    "    \n",
    "log_location = data_folder + \"logs/\"\n",
    "arquivo_fonte = data_folder + \"data/batch03/inputs/herval_final.xls\"\n",
    "arquivo_saida = data_folder + \"data/batch03/intermediate/Herval.normalized.pickle\"\n",
    "cluster_imagem = data_folder + \"data/batch03/intermediate/cluster.png\"\n",
    "\n",
    "pd.options.display.max_columns = 150\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.width', 10000)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuracao do log a ser usado no processo e funcao para imprimir tanto na tela quanto no log abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(message)s\",\n",
    "                    level=logging.DEBUG,\n",
    "                    filename=os.path.join(log_location,'prepare_data.log.' + \\\n",
    "                                          datetime.now().strftime(\"%Y%m%d%H%M%S.%f\") + '.log'))\n",
    "def print_log(x):\n",
    "    logging.debug(x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcao para limpar o dataframe de qualquer coluna desnecessario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_df(pagantes):\n",
    "    return pagantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcoes de limpeza de string para os tratamentos abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_str(x):\n",
    "    return str(x).replace(\" \",\"_\").upper().strip()\n",
    "\n",
    "def func_strip(x):\n",
    "    return str(x).strip()\n",
    "\n",
    "def func_start_ALTA(x):\n",
    "    return str(x).startswith('ALTA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversoes e funcoes para tratamento de coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConverterPAGOU(x):\n",
    "    return 1 if x == 1 else 0\n",
    "def ConverterSimNao(x):\n",
    "    return 1 if x == \"Sim\" else 0\n",
    "def print_colunas(df):\n",
    "    for coluna in pagantes.head(10).columns.values:\n",
    "        print_log(coluna)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary que define quais sao as funcoes a serem executadas quando carregamos o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converters = { \n",
    "    \"ESCOLARIDADE\" : func_str\n",
    "}\n",
    "df_dtypes = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le o excel passando  os tipos e conversores a serem usados em cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes = pd.read_excel(arquivo_fonte, dtype=df_dtypes, converters = converters)\n",
    "print_log(\"CSV carregado, limpando colunas desnecessarias\")\n",
    "print_colunas(pagantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpamos o dataframe de colunas indesejadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes = limpar_df(pagantes)\n",
    "print_log(\"-------------------------------------------\")\n",
    "print_log(\"Colunas Remanescentes...\")\n",
    "print_log(\"-------------------------------------------\")\n",
    "print_colunas(pagantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo todos os casos que CLIENTE_VALOR_DIVIDA e CONTRATO_ATRASO sao nulos (ou seja, np.nan) e apos resetando o indice interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes = pagantes[np.isfinite(pagantes['CLIENTE_VALOR_DIVIDA'])]\n",
    "pagantes = pagantes[np.isfinite(pagantes['CONTRATO_ATRASO'])]\n",
    "pagantes = pagantes.reset_index()\n",
    "#print_log(pagantes.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterizacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos criar um array de numpy com todos os dados de CLIENTE_VALOR_DIVIDA e CONTRATO_ATRASO de forma que possamos dai gerar uma clusterizacao para melhorar a precisao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_pagantes_para_cluster = pagantes[['CLIENTE_VALOR_DIVIDA','CONTRATO_ATRASO']]\n",
    "np_valores_pagantes_para_cluster = valores_pagantes_para_cluster.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com um numpy array com os dados de CLIENTE_VALOR_DIVIDA e CONTRATO_ATRASO podemos entao criar um cluster com 4 segmentacoes para melhorar a precisao do algoritmo, o id do cluster que sera determinado para cada linha do dataframe sera colocado na coluna CLUSTER do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pagantes = KMeans(n_clusters=4, random_state=0).fit(np_valores_pagantes_para_cluster)\n",
    "clusters = kmeans_pagantes.predict(np_valores_pagantes_para_cluster)\n",
    "pagantes['CLUSTER'] = pagantes.apply(lambda row: clusters[row.name] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizacao e depuracao, criamos uma figura para salvar o PNG e ver direitinho como ficou..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "if running_in_jupyter:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(np_valores_pagantes_para_cluster[:,0], np_valores_pagantes_para_cluster[:,1], c=clusters)\n",
    "    plt.savefig(cluster_imagem)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacao dos Dados e Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcoes especiais para parsear dados que vem em formato de string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseNumTelefone(x):\n",
    "    ret = np.nan\n",
    "    if str(x).startswith('['):\n",
    "        ret = x[1:]\n",
    "        ret = ret.split(';')[0]\n",
    "        ret = ret[0:2]\n",
    "    return ret\n",
    "\n",
    "def ParseRendaEstimada(x):\n",
    "    ret = np.nan\n",
    "    if str(x) == 'SEM INFORMACAO':\n",
    "        return ret\n",
    "    if len(str(x)) > 4:\n",
    "        ret = str(x)\n",
    "        ret = ret.replace('DE ',' ').replace(' A ', ' ').replace('SEM INFORMACAO', ' ').replace('ACIMA ', ' ').replace(',01',' ').replace('.','').replace('ATE ',' ')\n",
    "        ret = ret.replace('  ',' ')\n",
    "        ret = ret.strip()\n",
    "        ret = ret.split(' ')[0]\n",
    "        ret = int(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funcoes abaixo normalizam as colunas com valores continuos para um espaco de 0 a 1. e para valores discretos eh criada uma coluna a mais com o valor de 0 ou 1, no sentido do valor estar presente ou nao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma coluna para cada valor discreto daquela coluna, e atribui 1 ou 0 a essa coluna.\n",
    "def CreateColumnStr(cols, df, source_col):\n",
    "    for col in cols:\n",
    "        if str(col) == \"nan\":\n",
    "            continue\n",
    "        df['NORM_' + source_col + \"_\" + str(col)] = df.apply(lambda row: 1 if func_str(row[source_col]) == func_str(col) else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "# Em colunas com valores sequenciais, trunca o valor de cada coluna no maximo e no minimo\n",
    "def RemoveOutliers(df, source_col, min, max):\n",
    "    df['NORM_' + source_col] = df.apply(lambda row: 0   if row[source_col] < min else row[source_col] , axis=1)\n",
    "    df['NORM_' + source_col] = df.apply(lambda row: max if row[source_col] > max else row[source_col] , axis=1)\n",
    "    return df\n",
    "\n",
    "# Cria uma proporcao em termos de 0.0 a 1.0 em valores sequenciais, usando como o valor maximo: (media + (4*desvio_padrao))\n",
    "def CreateProportion(df, source_col):\n",
    "    max = df[source_col].mean() + (df[source_col].std() * 4 )\n",
    "    min = 0\n",
    "    \n",
    "    df = RemoveOutliers(df, source_col, min, max)\n",
    "    print_log(\"({}) - Valores entre {} e {:.2f}\".format(source_col, min, max))\n",
    "   \n",
    "    df['NORM_' + source_col] = df.apply(lambda row: 0 if row['NORM_' + source_col] == 0 else ((row['NORM_' + source_col] - min) / max) , axis=1)\n",
    "    return df\n",
    "\n",
    "#Cria colunas de telefone a partir do parse da string\n",
    "def CreateNumeroTelefone(df,source_col):\n",
    "    df['PARSED_' + source_col] = df.apply(lambda row: ParseNumTelefone(row[source_col]) , axis=1)\n",
    "    return df\n",
    "\n",
    "#Cria colunas de Renda Estimada a partir do parsing do texto da renda estimada\n",
    "def CreateRendaEstimada(df,source_col):\n",
    "    df['PARSED_' + source_col] = df.apply(lambda row: ParseRendaEstimada(row[source_col]) , axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso exista a coluna PAGOU no dataframe, entao normaliza ela..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PAGOU' in pagantes.head(10).columns.values:\n",
    "    pagantes['PAGOU'] = pagantes.apply(lambda row: 1 if row['PAGOU'] == 1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chama as funcoes acima para criar as colunas normalizadas com valores entre 0 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes = CreateProportion(pagantes, 'CLIENTE_VALOR_DIVIDA')\n",
    "pagantes = CreateProportion(pagantes, 'CONTRATO_ATRASO')\n",
    "pagantes = CreateProportion(pagantes, 'RENDA_PRESUMIDA')\n",
    "pagantes = CreateColumnStr(pagantes['ESCOLARIDADE'].unique(), pagantes, 'ESCOLARIDADE')\n",
    "pagantes = CreateColumnStr(pagantes['CLASSE_SOCIAL'].unique(), pagantes, 'CLASSE_SOCIAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos um dataframe com varias colunas, precisamos entao apenas selecionar as colunas que necessitamos manter no dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_processar = []\n",
    "if 'PAGOU' in pagantes.head(10).columns.values:\n",
    "   colunas_para_processar.append('PAGOU')\n",
    "if 'CLUSTER' in pagantes.head(10).columns.values:\n",
    "   colunas_para_processar.append('CLUSTER')\n",
    "if 'CPF' in pagantes.head(10).columns.values:\n",
    "   colunas_para_processar.append('CPF')\n",
    "\n",
    "for coluna in pagantes.head(10).columns.values:\n",
    "    if not coluna.startswith('NORM_'):\n",
    "        continue\n",
    "    colunas_para_processar.append(coluna)\n",
    "colunas_para_processar = sorted(list(set(colunas_para_processar)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez com as colunas selecionadas, podemos criar um dataframe apenas com elas e remover todas as linhas invalidas q tenham qualquer valor nulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes = pagantes[colunas_para_processar]\n",
    "pagantes = pagantes.dropna(axis = 0, how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gravamos o arquivo final normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes.to_pickle(arquivo_saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
