{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import gc\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import dateutil.parser as parser\n",
    "import os.path\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, confusion_matrix\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proporcao_train = 0.5\n",
    "proporcao_test = 0.5\n",
    "\n",
    "log_location = \"../../logs/\"\n",
    "arquivo_pagantes_norm = \"../../data/batch03/intermediate/Herval.normalized.pickle\"\n",
    "arquivo_pagantes_norm_train_x = \"../../data/batch03/intermediate/Herval.normalized.train.x.pickle\"\n",
    "\n",
    "txt_dump_model = \"../../data/batch03/intermediate/model_generated.txt\"\n",
    "txt_feat_map_model = \"../../data/batch03/intermediate/feat_map_generated.txt\"\n",
    "\n",
    "output_folder= \"../../data/batch03/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format=\"%(asctime)-15s %(message)s\",\n",
    "                    level=logging.DEBUG,\n",
    "                    filename=os.path.join(log_location,'xgboost.log.' + datetime.now().strftime(\"%Y%m%d%H%M%S.%f\") + '.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(msg):\n",
    "    logging.debug(msg)\n",
    "    print(msg)\n",
    "    \n",
    "def log(msg):\n",
    "    logging.debug(msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Carregando Pickling normalizado:{}\".format(arquivo_pagantes_norm))    \n",
    "pagantes = pd.read_pickle(arquivo_pagantes_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pagantes = len(pagantes.index)\n",
    "print_log(\"Total pagantes:{}\".format(total_pagantes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column_reference(header_chamadas_x,arquivo_df_pickled_norm_train_x):\n",
    "    print_log(\"Criando Arquivo de referencia de colunas...\")\n",
    "    with open(arquivo_df_pickled_norm_train_x+\".txt\",\"w\") as f:\n",
    "        counter = 0\n",
    "        lista_header = list(header_chamadas_x.columns.values)\n",
    "        for header in lista_header:\n",
    "            f.write(\"{}-{}\\n\".format(counter,header))\n",
    "            counter=counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log(\"Criando dataframes de train e teste...\")\n",
    "pagantes = pagantes.sample(int(len(pagantes.index)))\n",
    "pagantes_train = pagantes.tail(int(len(pagantes.index) * proporcao_train))\n",
    "pagantes_test = pagantes.head(int(len(pagantes.index) * proporcao_test))\n",
    "del pagantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_column_reference(pagantes_train.loc[:, :'NORM_RENDA_PRESUMIDA'].head(1), arquivo_pagantes_norm_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes_train_x = pagantes_train.loc[:, :'NORM_RENDA_PRESUMIDA']\n",
    "pagantes_train_y = pagantes_train.loc[:, 'PAGOU':'PAGOU']\n",
    "\n",
    "pagantes_test_x = pagantes_test.loc[:, :'NORM_RENDA_PRESUMIDA']\n",
    "pagantes_test_y = pagantes_test.loc[:, 'PAGOU':'PAGOU']\n",
    "\n",
    "colunas_x = pagantes_train_x.columns.values\n",
    "colunas_y = pagantes_train_y.columns.values\n",
    "\n",
    "pagantes_train_x = pagantes_train_x.as_matrix()\n",
    "pagantes_train_y = pagantes_train_y.as_matrix()\n",
    "\n",
    "pagantes_test_x = pagantes_test_x.as_matrix()\n",
    "pagantes_test_y = pagantes_test_y.as_matrix()\n",
    "\n",
    "colunas_x = [x for x in colunas_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1 = \"Train - Pagantes Detectados {} num universo de {}\".format(len([y for y in pagantes_train_y if y >0]),len(pagantes_train_y))\n",
    "msg2 = \"Test - Pagantes Detectados {} num universo de {}\".format(len([y for y in pagantes_test_y if y >0]),len(pagantes_test_y))\n",
    "print_log(msg1)\n",
    "print_log(msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagantes = (len([y for y in pagantes_train_y if y >0]),len(pagantes_train_y))\n",
    "print(pagantes)\n",
    "ratio = pagantes[1] / pagantes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_trees = 1\n",
    "max_trees = 20\n",
    "model_batch = datetime.now().strftime(\"%Y%m%d.%H%M%S\")\n",
    "for eta in [0.3]:\n",
    "    for depth in [4]:\n",
    "        for x in range(min_trees, max_trees):\n",
    "            param = {}\n",
    "            param['booster'] = 'gbtree'\n",
    "            param['eta'] = eta\n",
    "            param['objective'] = 'binary:logistic'\n",
    "            param['eval_metric'] = 'auc'\n",
    "            param['tree_method'] = 'auto'\n",
    "            param['silent'] = 0\n",
    "            param['max_depth'] = depth\n",
    "            param['subsample'] = 0.5\n",
    "            num_round = x\n",
    "            gc.collect()\n",
    "            #print_log(\"Starting model for params:{}\".format(param))\n",
    "            dtrain = xgb.DMatrix(pagantes_train_x, pagantes_train_y, feature_names = colunas_x)\n",
    "            dtest = xgb.DMatrix(pagantes_test_x, pagantes_test_y, feature_names = colunas_x)\n",
    "            train_labels = dtrain.get_label()\n",
    "            ratio = float(np.sum(train_labels == 0)) / np.sum(train_labels == 1) \n",
    "            param['scale_pos_weight'] = ratio\n",
    "            #print_log(\"ratio:{}\".format(ratio))\n",
    "            gpu_res = {}\n",
    "            booster = xgb.train(param, dtrain, num_round, evals_result=gpu_res, evals = [])\n",
    "\n",
    "            booster.dump_model(os.path.join(output_folder,\"{}.{}.txt\".format(model_batch,x)))\n",
    "            print_log(sorted( ((v,k) for k,v in booster.get_score().items()), reverse=True))\n",
    "\n",
    "            train_y_pred = booster.predict(dtrain)\n",
    "            train_predictions = np.array([value for value in train_y_pred])\n",
    "            pagantes_train_y = pagantes_train_y.astype('float32')\n",
    "            train_predictions = train_predictions.astype('float32').round()\n",
    "            tn, fp, fn, tp = confusion_matrix(np.squeeze(pagantes_train_y), np.squeeze(train_predictions)).ravel()\n",
    "            msg = \"(TRAIN)Number of Trees:{}, eta:{}, depth:{} \".format(x, eta, depth) + \"True Positive:{} True Negative:{} False Positive:{} False Negative:{},  {}% de acerto no train\".format(tp, tn, fp, fn, (1 - ((fp+fn)/ (tp+tn))) * 100 )\n",
    "            print_log(msg)\n",
    "\n",
    "            test_y_pred = booster.predict(dtest)\n",
    "            test_predictions = np.array([value for value in test_y_pred])\n",
    "            test_predictions = np.array([1 if x > 0.30 else 0 for x in test_predictions])\n",
    "            pagantes_test_y = pagantes_test_y.astype('float32')\n",
    "            test_predictions = test_predictions.astype('float32').round()\n",
    "            tn, fp, fn, tp = confusion_matrix(np.squeeze(pagantes_test_y), np.squeeze(test_predictions)).ravel()\n",
    "            msg = \"(TEST)Number of Trees:{}, eta:{}, depth:{} \".format(x, eta, depth) + \"True Positive:{} True Negative:{} False Positive:{} False Negative:{},  {}% de falso negativo no test\".format(tp, tn, fp, fn,  (fn / (tp + tn + fp + fn) * 100))\n",
    "            print_log(msg)\n",
    "\n",
    "            if False and x == (max_trees - 1):\n",
    "                falso_negativos = []\n",
    "                for cur_sample in range(len(pagantes_test_x)):\n",
    "                    if pagantes_test_y[cur_sample] == 1 and test_predictions[cur_sample] == 0:\n",
    "                        falso_negativos.append(pagantes_test_x[cur_sample])\n",
    "\n",
    "                print_log(len(falso_negativos))\n",
    "                for cur_falso_negativo in falso_negativos:\n",
    "                    print_log(cur_falso_negativo)\n",
    "                break\n",
    "\n",
    "            save_file = os.path.join(output_folder,\"{}.{}.model\".format(model_batch,x))\n",
    "            with open(save_file, 'wb') as fp:\n",
    "                pickle.dump(booster, fp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
